{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep learning com pytorch:datasets e fluxo de validação.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNdWLCn4gLQZiTXO4hA6jcV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otavioaugusto1/Deep-Learning-with-PyTorch/blob/main/Deep_learning_com_pytorch_datasets_e_fluxo_de_valida%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdrg-pe_Qot5"
      },
      "source": [
        "**Carregamento de Dados**\n",
        "Objetivos dessa aula:\n",
        "\n",
        "**Carregar um dataset customizado**\n",
        "Implementar o fluxo de treinamento e validação completo de uma rede\n",
        "Hiperparâmetros\n",
        "Vamos manter a organização do último script :)\n",
        "\n",
        "**imports de pacotes**\n",
        "configuração de hiperparâmetros\n",
        "definição do hardware padrão utilizado\n",
        "E bora de GPU de novo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp1XyDSOQBxy",
        "outputId": "f38e6fdc-5419-439d-cc4c-5ea3fdac009c"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Configurando hiperparâmetros.\n",
        "args = {\n",
        "    'epoch_num': 200,     # Número de épocas.\n",
        "    'lr': 5e-5,           # Taxa de aprendizado.\n",
        "    'weight_decay': 5e-4, # Penalidade L2 (Regularização).\n",
        "    'num_workers': 3,     # Número de threads do dataloader.\n",
        "    'batch_size': 20,     # Tamanho do batch.\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vectL0ndQyB3"
      },
      "source": [
        "**Dataset**\n",
        "Dataset de aplicativos para aluguel de bicicletas (Bike Sharing Dataset).\n",
        "\n",
        "Dadas algumas informações como velocidade do vento, estação do ano, etc., quantas bicicletas serão alugadas na próxima hora?\n",
        "\n",
        "Esse é um problema de Regressão, onde precisamos estimar uma variável dependente em um espaço contínuo (alugueis de bikes) a partir de um conjunto de variáveis independentes (as condições no momento).\n",
        "\n",
        "**Baixando o dataset**\n",
        "Fonte: https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shVJ9Ik-Qutv",
        "outputId": "d1a6388c-bf66-41ca-a4c2-9cd61efef2d5"
      },
      "source": [
        "\n",
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
        "! unzip Bike-Sharing-Dataset.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-13 01:07:21--  https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 279992 (273K) [application/x-httpd-php]\n",
            "Saving to: ‘Bike-Sharing-Dataset.zip’\n",
            "\n",
            "Bike-Sharing-Datase 100%[===================>] 273.43K   855KB/s    in 0.3s    \n",
            "\n",
            "2021-05-13 01:07:21 (855 KB/s) - ‘Bike-Sharing-Dataset.zip’ saved [279992/279992]\n",
            "\n",
            "Archive:  Bike-Sharing-Dataset.zip\n",
            "  inflating: Readme.txt              \n",
            "  inflating: day.csv                 \n",
            "  inflating: hour.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfcvuIszQ8Xo"
      },
      "source": [
        "Visualizando os dados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "YCenJmYJQ4Z5",
        "outputId": "909294d4-ac9a-4788-c15e-8e15207cf475"
      },
      "source": [
        "\n",
        "df = pd.read_csv('hour.csv')\n",
        "print(len(df))\n",
        "df.head()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "0        1  2011-01-01       1   0  ...        0.0       3          13   16\n",
              "1        2  2011-01-01       1   0  ...        0.0       8          32   40\n",
              "2        3  2011-01-01       1   0  ...        0.0       5          27   32\n",
              "3        4  2011-01-01       1   0  ...        0.0       3          10   13\n",
              "4        5  2011-01-01       1   0  ...        0.0       0           1    1\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04Zvs8CCRAUg"
      },
      "source": [
        "**Tratamento de dados**\n",
        "\n",
        "**Variáveis Categóricas**\n",
        "\n",
        "Como descrito na página do dataset, apenas as variáveis numéricas estão normalizadas. No caso das categóricas (como dia da semana e estação do ano), cada elemento contém o índice da categoria.\n",
        "\n",
        "Existem várias formas de lidar com variáveis categóricas em uma regressão, mas para não desviar o foco da nossa aula manteremos os valores originais das variáveis categóricas.\n",
        "\n",
        "**Separação em treino e teste**\n",
        "\n",
        "Para treinar e validar o nosso modelo, precisamos de dois conjuntos de dados (treino e teste). Para isso, utilizaremos a função torch.randperm para amostrar aleatoriamente um percentual dos dados, separando-os para validação.\n",
        "\n",
        "Documentação: https://pytorch.org/docs/stable/torch.html#torch.randperm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "xivPsaDnQ-hv",
        "outputId": "1df0ce90-397b-4060-cc07-41ce9e47511b"
      },
      "source": [
        "# Train/Test split\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(df)).tolist()\n",
        "\n",
        "train_size = int(0.8*len(df))\n",
        "df_train = df.iloc[indices[:train_size]]\n",
        "df_test  = df.iloc[indices[train_size:]]\n",
        "\n",
        "print(len(df_train), len(df_test))\n",
        "display(df_test.head())\n",
        "\n",
        "df_train.to_csv('bike_train.csv',index=False)\n",
        "df_test.to_csv('bike_test.csv',index=False)\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13903 3476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12663</th>\n",
              "      <td>12664</td>\n",
              "      <td>2012-06-16</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.6212</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.1940</td>\n",
              "      <td>123</td>\n",
              "      <td>229</td>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1801</th>\n",
              "      <td>1802</td>\n",
              "      <td>2011-03-20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.3939</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.3582</td>\n",
              "      <td>58</td>\n",
              "      <td>98</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16567</th>\n",
              "      <td>16568</td>\n",
              "      <td>2012-11-28</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.2239</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8817</th>\n",
              "      <td>8818</td>\n",
              "      <td>2012-01-08</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1045</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>2609</td>\n",
              "      <td>2011-04-23</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.5455</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.3582</td>\n",
              "      <td>182</td>\n",
              "      <td>209</td>\n",
              "      <td>391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       instant      dteday  season  yr  ...  windspeed  casual  registered  cnt\n",
              "12663    12664  2012-06-16       2   1  ...     0.1940     123         229  352\n",
              "1801      1802  2011-03-20       1   0  ...     0.3582      58          98  156\n",
              "16567    16568  2012-11-28       4   1  ...     0.2239       0          12   12\n",
              "8817      8818  2012-01-08       1   1  ...     0.1045       0           2    2\n",
              "2608      2609  2011-04-23       2   0  ...     0.3582     182         209  391\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Bike-Sharing-Dataset.zip  bike_train.csv  hour.csv    sample_data\n",
            "bike_test.csv\t\t  day.csv\t  Readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwkDUv3gRKEQ"
      },
      "source": [
        "**Classe Dataset**\n",
        "\n",
        "O pacote torch.util.data possui a classe abstrata Dataset. Ela permite que você implemente o seu próprio dataset reescrevendo os métodos:\n",
        "\n",
        "    __init__(self): Define a lista de amostras do seu dataset\n",
        "    __getitem__(self, idx): Carrega uma amostra, aplica as devidas transformações e retorna uma tupla (dado, rótulo).\n",
        "    __len__(self): Retorna a quantidade de amostras do dataset\n",
        "\n",
        "Tutorial completo do PyTorch: \n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IENwdtTTRHy2"
      },
      "source": [
        "class Bicicletinha(Dataset):\n",
        "  def __init__(self, csv_path, scaler_feat=None, scaler_label=None):\n",
        "  \n",
        "    self.dados = pd.read_csv(csv_path).to_numpy()\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    sample = self.dados[idx][2:14]\n",
        "    label  = self.dados[idx][-1:]\n",
        "    \n",
        "    # converte para tensor\n",
        "    sample = torch.from_numpy(sample.astype(np.float32))\n",
        "    label  = torch.from_numpy(label.astype(np.float32))\n",
        "    \n",
        "    return sample, label\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.dados)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap9qe0nkRSL7",
        "outputId": "912d6036-8a55-49e9-e527-c69afe656984"
      },
      "source": [
        "dataset = Bicicletinha('bike_train.csv')\n",
        "dado, rotulo = dataset[0]\n",
        "print(rotulo)\n",
        "print(dado)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([373.])\n",
            "tensor([ 4.0000,  1.0000, 11.0000, 19.0000,  0.0000,  4.0000,  1.0000,  1.0000,\n",
            "         0.3800,  0.3939,  0.2700,  0.3582])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GGiJsdVRVYK"
      },
      "source": [
        "**Construindo conjuntos de treino e teste**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxamWUDzRTnJ",
        "outputId": "9e80c926-7370-499d-e248-72de2fb1ed12"
      },
      "source": [
        "train_set = Bicicletinha('bike_train.csv')\n",
        "test_set  = Bicicletinha('bike_test.csv')\n",
        "\n",
        "print('Tamanho do treino: ' + str(len(train_set)) + ' amostras')\n",
        "print('Tamanho do teste: ' + str(len(test_set)) + ' amostras')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho do treino: 13903 amostras\n",
            "Tamanho do teste: 3476 amostras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6nSBTTHRaVf"
      },
      "source": [
        "\n",
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsL8GPw6RYSQ",
        "outputId": "94286088-9e91-41e0-936b-85ec63100376"
      },
      "source": [
        "# Criando dataloader\n",
        "train_loader = DataLoader(train_set,\n",
        "                          args['batch_size'],\n",
        "                          num_workers=args['num_workers'],\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         args['batch_size'],\n",
        "                         num_workers=args['num_workers'],\n",
        "                         shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooz_A_13Rfh_"
      },
      "source": [
        "O objeto retornado é um iterador, podendo ser utilizado para iterar em loops mas não suportando indexação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtQb3yxrRdve",
        "outputId": "beb96505-1aff-4a32-b607-fc41fe4fee09"
      },
      "source": [
        "for batch in test_loader:\n",
        "  \n",
        "  dado, rotulo = batch\n",
        "  print('## Dimensionalidade do batch ##')\n",
        "  print(dado.size(), rotulo.size())\n",
        "  \n",
        "  break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "## Dimensionalidade do batch ##\n",
            "torch.Size([20, 12]) torch.Size([20, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeHZJ5B0RjLQ"
      },
      "source": [
        "**Implementando o MLP**\n",
        "Essa parte aqui você já tira de letra! Minha sugestão é construir um modelo com:\n",
        "\n",
        "Duas camadas escondidas. Lembre-se de alternar as camadas com ativações não-lineares.\n",
        "Uma camada de saída (com qual ativação?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPRCIIYmRhJm",
        "outputId": "0bf74e80-f59d-4e23-ca88-b08ba040f2f7"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, out_size):\n",
        "    super(MLP, self).__init__()\n",
        "    \n",
        "    self.features = nn.Sequential(\n",
        "          nn.Linear(input_size, hidden_size),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(hidden_size, hidden_size),\n",
        "          nn.ReLU(),\n",
        "    )\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(hidden_size, out_size),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    \n",
        "    hidden = self.features(X)\n",
        "    output = self.classifier(hidden)\n",
        "    \n",
        "    return output\n",
        "\n",
        "input_size  = train_set[0][0].size(0)\n",
        "hidden_size = 128\n",
        "out_size    = 1\n",
        "\n",
        "net = MLP(input_size, hidden_size, out_size).to(args['device'])\n",
        "print(net)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (features): Sequential(\n",
            "    (0): Linear(in_features=12, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaskC9ckRpdY"
      },
      "source": [
        "**Definindo loss e otimizador**\n",
        "\n",
        "Se lembra quais as funções de perda adequadas para um problema de regressão?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm6ZR_auRm_L"
      },
      "source": [
        "criterion = nn.L1Loss().to(args['device'])\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La6SJ3x8SFWI"
      },
      "source": [
        "## **Fluxo de Treinamento & Validação**\n",
        "Treinamento\n",
        "Relembrando o passo a passo do fluxo de treinamento:\n",
        "\n",
        "Iterar nas épocas\n",
        "\n",
        "Iterar nos batches\n",
        "\n",
        "Cast dos dados no dispositivo de hardware\n",
        "\n",
        "Forward na rede e cálculo da loss\n",
        "\n",
        "Cálculo do gradiente e atualização dos pesos\n",
        "\n",
        "Esse conjunto de passos é responsável pelo processo iterativo de otimização de uma rede. A validação por outro lado, é apenas a aplicação da rede em dados nunca antes visto para estimar a qualidade do modelo no mundo real.\n",
        "\n",
        "Validação\n",
        "\n",
        "Para essa etapa, o PyTorch oferece dois artifícios:\n",
        "\n",
        "model.eval(): Impacta no forward da rede, informando as camadas caso seu comportamento mude entre fluxos (ex: dropout).\n",
        "with torch.no_grad(): Gerenciador de contexto que desabilita o cálculo e armazenamento de gradientes (economia de tempo e memória). Todo o código de validação deve ser executado dentro desse contexto.\n",
        "Exemplo de código para validação\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in test_loader:\n",
        "          # Código de validação\n",
        "    Existe o equivalente ao model.eval() para explicitar que a sua rede deve estar em modo de treino, é o model.train(). Apesar de ser o padrão dos modelos, é boa prática definir também o modo de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RJ3-eTRRseC"
      },
      "source": [
        "def train(train_loader, net, epoch):\n",
        "\n",
        "  # Training mode\n",
        "  net.train()\n",
        "  \n",
        "  start = time.time()\n",
        "  \n",
        "  epoch_loss  = []\n",
        "  for batch in train_loader:\n",
        "    \n",
        "    dado, rotulo = batch\n",
        "    \n",
        "    # Cast do dado na GPU\n",
        "    dado = dado.to(args['device'])\n",
        "    rotulo = rotulo.to(args['device'])\n",
        "    \n",
        "    # Forward\n",
        "    ypred = net(dado)\n",
        "    loss = criterion(ypred, rotulo)\n",
        "    epoch_loss.append(loss.cpu().data)\n",
        "    \n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "   \n",
        "  epoch_loss = np.asarray(epoch_loss)\n",
        "  \n",
        "  end = time.time()\n",
        "  print('#################### Train ####################')\n",
        "  print('Epoch %d, Loss: %.4f +/- %.4f, Time: %.2f' % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
        "  \n",
        "  return epoch_loss.mean()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkIC0TsESR5c"
      },
      "source": [
        "def validate(test_loader, net, epoch):\n",
        "\n",
        "  # Evaluation mode\n",
        "  net.eval()\n",
        "  \n",
        "  start = time.time()\n",
        "  \n",
        "  epoch_loss  = []\n",
        "  \n",
        "  with torch.no_grad(): \n",
        "    for batch in test_loader:\n",
        "\n",
        "      dado, rotulo = batch\n",
        "\n",
        "      # Cast do dado na GPU\n",
        "      dado = dado.to(args['device'])\n",
        "      rotulo = rotulo.to(args['device'])\n",
        "\n",
        "      # Forward\n",
        "      ypred = net(dado)\n",
        "      loss = criterion(ypred, rotulo)\n",
        "      epoch_loss.append(loss.cpu().data)\n",
        "\n",
        "  epoch_loss = np.asarray(epoch_loss)\n",
        "  \n",
        "  end = time.time()\n",
        "  print('********** Validate **********')\n",
        "  print('Epoch %d, Loss: %.4f +/- %.4f, Time: %.2f\\n' % (epoch, epoch_loss.mean(), epoch_loss.std(), end-start))\n",
        "  \n",
        "  return epoch_loss.mean()\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT_YsLOtSU1F",
        "outputId": "5edfc2c0-4ba7-4c39-9fb5-18954e1c8499"
      },
      "source": [
        "train_losses, test_losses = [], []\n",
        "for epoch in range(args['epoch_num']):\n",
        "  \n",
        "  # Train\n",
        "  train_losses.append(train(train_loader, net, epoch))\n",
        "  \n",
        "  # Validate\n",
        "  test_losses.append(validate(test_loader, net, epoch))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "#################### Train ####################\n",
            "Epoch 0, Loss: 164.3091 +/- 41.8290, Time: 2.75\n",
            "********** Validate **********\n",
            "Epoch 0, Loss: 126.1877 +/- 30.5127, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 1, Loss: 132.0851 +/- 25.0518, Time: 2.54\n",
            "********** Validate **********\n",
            "Epoch 1, Loss: 127.3917 +/- 24.2552, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 2, Loss: 123.5236 +/- 29.5951, Time: 2.57\n",
            "********** Validate **********\n",
            "Epoch 2, Loss: 127.1817 +/- 31.9073, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 3, Loss: 122.3897 +/- 31.0318, Time: 2.62\n",
            "********** Validate **********\n",
            "Epoch 3, Loss: 116.1245 +/- 26.5783, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 4, Loss: 120.4208 +/- 26.0317, Time: 2.87\n",
            "********** Validate **********\n",
            "Epoch 4, Loss: 115.0319 +/- 27.3075, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 5, Loss: 119.6440 +/- 29.9864, Time: 2.85\n",
            "********** Validate **********\n",
            "Epoch 5, Loss: 119.6545 +/- 31.0075, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 6, Loss: 116.5691 +/- 28.1603, Time: 2.89\n",
            "********** Validate **********\n",
            "Epoch 6, Loss: 120.6641 +/- 27.2274, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 7, Loss: 116.7325 +/- 26.8338, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 7, Loss: 115.6048 +/- 30.1076, Time: 0.54\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 8, Loss: 114.3825 +/- 29.3999, Time: 3.05\n",
            "********** Validate **********\n",
            "Epoch 8, Loss: 112.5644 +/- 26.1375, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 9, Loss: 111.9032 +/- 26.0059, Time: 3.21\n",
            "********** Validate **********\n",
            "Epoch 9, Loss: 109.0984 +/- 28.2681, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 10, Loss: 109.0224 +/- 28.1082, Time: 3.44\n",
            "********** Validate **********\n",
            "Epoch 10, Loss: 106.2192 +/- 25.2054, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 11, Loss: 104.9384 +/- 25.4368, Time: 3.34\n",
            "********** Validate **********\n",
            "Epoch 11, Loss: 102.4691 +/- 26.9372, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 12, Loss: 100.7229 +/- 25.9319, Time: 3.40\n",
            "********** Validate **********\n",
            "Epoch 12, Loss: 97.9539 +/- 24.2030, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 13, Loss: 97.9218 +/- 24.9879, Time: 3.36\n",
            "********** Validate **********\n",
            "Epoch 13, Loss: 95.1083 +/- 25.1674, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 14, Loss: 97.1954 +/- 23.3098, Time: 3.36\n",
            "********** Validate **********\n",
            "Epoch 14, Loss: 95.5361 +/- 25.1335, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 15, Loss: 96.9530 +/- 24.1045, Time: 3.27\n",
            "********** Validate **********\n",
            "Epoch 15, Loss: 92.0550 +/- 22.5176, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 16, Loss: 95.3052 +/- 23.9675, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 16, Loss: 94.9981 +/- 21.2292, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 17, Loss: 93.5624 +/- 23.9633, Time: 3.33\n",
            "********** Validate **********\n",
            "Epoch 17, Loss: 89.9956 +/- 21.8605, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 18, Loss: 93.9572 +/- 23.1294, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 18, Loss: 92.1528 +/- 24.6158, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 19, Loss: 92.6585 +/- 21.7730, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 19, Loss: 92.0404 +/- 24.4071, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 20, Loss: 92.6438 +/- 22.9730, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 20, Loss: 87.5119 +/- 21.7627, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 21, Loss: 91.1799 +/- 22.3513, Time: 3.30\n",
            "********** Validate **********\n",
            "Epoch 21, Loss: 92.6386 +/- 20.9775, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 22, Loss: 90.1486 +/- 23.6597, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 22, Loss: 86.4917 +/- 22.0040, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 23, Loss: 90.7318 +/- 23.6629, Time: 3.28\n",
            "********** Validate **********\n",
            "Epoch 23, Loss: 91.3481 +/- 25.4392, Time: 0.58\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 24, Loss: 89.8058 +/- 22.2570, Time: 3.26\n",
            "********** Validate **********\n",
            "Epoch 24, Loss: 86.1672 +/- 23.0701, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 25, Loss: 89.5235 +/- 24.4221, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 25, Loss: 90.8263 +/- 21.6498, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 26, Loss: 89.6473 +/- 24.4417, Time: 3.23\n",
            "********** Validate **********\n",
            "Epoch 26, Loss: 85.9338 +/- 24.2146, Time: 0.52\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 27, Loss: 87.2712 +/- 21.5296, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 27, Loss: 86.9057 +/- 24.6362, Time: 0.53\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 28, Loss: 87.1067 +/- 22.6425, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 28, Loss: 83.5045 +/- 22.3913, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 29, Loss: 85.9418 +/- 21.6090, Time: 3.20\n",
            "********** Validate **********\n",
            "Epoch 29, Loss: 86.0250 +/- 20.9915, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 30, Loss: 85.3203 +/- 21.8890, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 30, Loss: 86.3186 +/- 20.9118, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 31, Loss: 84.7048 +/- 22.4131, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 31, Loss: 82.0378 +/- 21.4745, Time: 0.52\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 32, Loss: 85.2737 +/- 22.8398, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 32, Loss: 82.7170 +/- 23.5247, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 33, Loss: 84.1623 +/- 21.7513, Time: 3.03\n",
            "********** Validate **********\n",
            "Epoch 33, Loss: 84.8433 +/- 24.5890, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 34, Loss: 83.4739 +/- 21.8807, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 34, Loss: 80.7003 +/- 22.8340, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 35, Loss: 83.5702 +/- 22.7466, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 35, Loss: 81.5807 +/- 20.7271, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 36, Loss: 82.7416 +/- 22.8873, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 36, Loss: 84.1411 +/- 20.6604, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 37, Loss: 83.1132 +/- 23.0666, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 37, Loss: 78.6129 +/- 21.7452, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 38, Loss: 82.4114 +/- 22.2165, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 38, Loss: 83.2534 +/- 24.1686, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 39, Loss: 82.0623 +/- 21.9166, Time: 3.02\n",
            "********** Validate **********\n",
            "Epoch 39, Loss: 77.8661 +/- 22.3214, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 40, Loss: 82.6404 +/- 23.5915, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 40, Loss: 84.9589 +/- 20.4364, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 41, Loss: 81.2697 +/- 23.1763, Time: 2.95\n",
            "********** Validate **********\n",
            "Epoch 41, Loss: 76.4992 +/- 21.7748, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 42, Loss: 80.2760 +/- 21.9072, Time: 3.02\n",
            "********** Validate **********\n",
            "Epoch 42, Loss: 80.4743 +/- 23.5537, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 43, Loss: 79.7270 +/- 21.5472, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 43, Loss: 75.3610 +/- 21.2808, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 44, Loss: 78.8693 +/- 21.6440, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 44, Loss: 80.2876 +/- 20.1561, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 45, Loss: 78.2612 +/- 21.5781, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 45, Loss: 74.1617 +/- 21.0187, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 46, Loss: 78.7948 +/- 21.5952, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 46, Loss: 78.4113 +/- 22.9590, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 47, Loss: 77.1371 +/- 20.4014, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 47, Loss: 74.3250 +/- 22.0084, Time: 0.54\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 48, Loss: 77.1763 +/- 20.8032, Time: 3.04\n",
            "********** Validate **********\n",
            "Epoch 48, Loss: 75.1089 +/- 19.5771, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 49, Loss: 75.0914 +/- 21.7328, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 49, Loss: 74.1795 +/- 19.9129, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 50, Loss: 74.9310 +/- 20.8390, Time: 3.02\n",
            "********** Validate **********\n",
            "Epoch 50, Loss: 70.5584 +/- 19.9126, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 51, Loss: 74.8063 +/- 21.5189, Time: 3.19\n",
            "********** Validate **********\n",
            "Epoch 51, Loss: 74.7461 +/- 22.0926, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 52, Loss: 73.6979 +/- 20.8360, Time: 3.00\n",
            "********** Validate **********\n",
            "Epoch 52, Loss: 73.1857 +/- 21.5152, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 53, Loss: 73.5559 +/- 20.2285, Time: 2.99\n",
            "********** Validate **********\n",
            "Epoch 53, Loss: 68.7785 +/- 19.7027, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 54, Loss: 72.3148 +/- 20.1137, Time: 3.03\n",
            "********** Validate **********\n",
            "Epoch 54, Loss: 70.8944 +/- 19.0043, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 55, Loss: 71.2672 +/- 19.3879, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 55, Loss: 71.0995 +/- 18.5437, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 56, Loss: 70.4045 +/- 19.6266, Time: 2.87\n",
            "********** Validate **********\n",
            "Epoch 56, Loss: 70.3897 +/- 18.2632, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 57, Loss: 70.5897 +/- 19.8139, Time: 2.94\n",
            "********** Validate **********\n",
            "Epoch 57, Loss: 66.7579 +/- 19.2257, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 58, Loss: 70.4356 +/- 19.6202, Time: 2.88\n",
            "********** Validate **********\n",
            "Epoch 58, Loss: 67.9764 +/- 20.2988, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 59, Loss: 70.7500 +/- 18.5531, Time: 2.83\n",
            "********** Validate **********\n",
            "Epoch 59, Loss: 72.2417 +/- 21.2849, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 60, Loss: 70.5977 +/- 18.9369, Time: 2.95\n",
            "********** Validate **********\n",
            "Epoch 60, Loss: 67.9584 +/- 20.1793, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 61, Loss: 71.3908 +/- 20.0418, Time: 2.96\n",
            "********** Validate **********\n",
            "Epoch 61, Loss: 70.6482 +/- 18.8445, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 62, Loss: 70.0691 +/- 19.0653, Time: 2.93\n",
            "********** Validate **********\n",
            "Epoch 62, Loss: 70.1794 +/- 17.7498, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 63, Loss: 68.7149 +/- 19.4060, Time: 3.02\n",
            "********** Validate **********\n",
            "Epoch 63, Loss: 64.3843 +/- 18.1937, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 64, Loss: 68.6539 +/- 18.4949, Time: 2.93\n",
            "********** Validate **********\n",
            "Epoch 64, Loss: 64.6592 +/- 18.6174, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 65, Loss: 68.2897 +/- 18.8590, Time: 2.89\n",
            "********** Validate **********\n",
            "Epoch 65, Loss: 69.4083 +/- 18.7261, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 66, Loss: 68.8585 +/- 17.6404, Time: 2.93\n",
            "********** Validate **********\n",
            "Epoch 66, Loss: 68.2345 +/- 19.3960, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 67, Loss: 67.8088 +/- 17.9938, Time: 2.89\n",
            "********** Validate **********\n",
            "Epoch 67, Loss: 66.2098 +/- 17.8011, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 68, Loss: 67.3997 +/- 18.1266, Time: 2.93\n",
            "********** Validate **********\n",
            "Epoch 68, Loss: 63.4945 +/- 18.2560, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 69, Loss: 66.6078 +/- 17.8153, Time: 3.00\n",
            "********** Validate **********\n",
            "Epoch 69, Loss: 63.3109 +/- 18.0735, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 70, Loss: 66.0580 +/- 17.6481, Time: 2.99\n",
            "********** Validate **********\n",
            "Epoch 70, Loss: 64.9884 +/- 17.6422, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 71, Loss: 65.4032 +/- 17.7861, Time: 3.03\n",
            "********** Validate **********\n",
            "Epoch 71, Loss: 65.1086 +/- 18.8740, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 72, Loss: 64.7472 +/- 18.9661, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 72, Loss: 63.8533 +/- 17.3416, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 73, Loss: 64.4192 +/- 17.9982, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 73, Loss: 63.4750 +/- 16.9505, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 74, Loss: 64.6494 +/- 18.4197, Time: 3.15\n",
            "********** Validate **********\n",
            "Epoch 74, Loss: 65.2135 +/- 18.0503, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 75, Loss: 64.3066 +/- 17.7553, Time: 3.23\n",
            "********** Validate **********\n",
            "Epoch 75, Loss: 63.4133 +/- 16.8121, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 76, Loss: 63.4507 +/- 17.6620, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 76, Loss: 62.7739 +/- 16.7255, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 77, Loss: 63.7681 +/- 17.2347, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 77, Loss: 64.6633 +/- 17.9114, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 78, Loss: 63.3475 +/- 17.6241, Time: 3.16\n",
            "********** Validate **********\n",
            "Epoch 78, Loss: 62.3677 +/- 16.4757, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 79, Loss: 63.1168 +/- 18.3737, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 79, Loss: 63.1177 +/- 17.2356, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 80, Loss: 63.6472 +/- 17.9180, Time: 3.22\n",
            "********** Validate **********\n",
            "Epoch 80, Loss: 62.5085 +/- 18.2128, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 81, Loss: 63.1471 +/- 17.6157, Time: 3.15\n",
            "********** Validate **********\n",
            "Epoch 81, Loss: 61.6703 +/- 16.8027, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 82, Loss: 63.1651 +/- 17.0312, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 82, Loss: 63.4929 +/- 16.8767, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 83, Loss: 63.3398 +/- 18.0288, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 83, Loss: 61.2300 +/- 17.9233, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 84, Loss: 62.7850 +/- 17.6148, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 84, Loss: 61.6173 +/- 17.7489, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 85, Loss: 62.2515 +/- 17.4809, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 85, Loss: 61.2352 +/- 16.7263, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 86, Loss: 62.3841 +/- 16.6939, Time: 3.05\n",
            "********** Validate **********\n",
            "Epoch 86, Loss: 62.7066 +/- 17.0102, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 87, Loss: 62.8596 +/- 16.8520, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 87, Loss: 62.0422 +/- 18.0379, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 88, Loss: 63.3374 +/- 16.4707, Time: 3.03\n",
            "********** Validate **********\n",
            "Epoch 88, Loss: 61.1014 +/- 18.1695, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 89, Loss: 63.0841 +/- 17.6672, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 89, Loss: 64.1769 +/- 18.4890, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 90, Loss: 63.6766 +/- 17.0533, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 90, Loss: 63.4474 +/- 18.8524, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 91, Loss: 64.0780 +/- 17.0911, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 91, Loss: 63.9269 +/- 17.6781, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 92, Loss: 64.1540 +/- 16.8358, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 92, Loss: 63.5909 +/- 17.1141, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 93, Loss: 63.4639 +/- 18.8014, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 93, Loss: 66.9416 +/- 17.1932, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 94, Loss: 62.7788 +/- 18.0397, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 94, Loss: 62.7163 +/- 17.0700, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 95, Loss: 62.9138 +/- 18.7791, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 95, Loss: 61.7021 +/- 16.5494, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 96, Loss: 62.0494 +/- 16.8754, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 96, Loss: 62.6074 +/- 18.3857, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 97, Loss: 62.3441 +/- 17.1356, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 97, Loss: 62.5470 +/- 17.6040, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 98, Loss: 61.9371 +/- 17.2467, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 98, Loss: 60.5304 +/- 16.8920, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 99, Loss: 61.9805 +/- 16.3161, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 99, Loss: 63.5518 +/- 16.4218, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 100, Loss: 61.1619 +/- 16.9793, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 100, Loss: 63.3565 +/- 16.3531, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 101, Loss: 60.7736 +/- 16.7825, Time: 3.16\n",
            "********** Validate **********\n",
            "Epoch 101, Loss: 61.7540 +/- 16.2659, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 102, Loss: 61.1893 +/- 16.2075, Time: 3.15\n",
            "********** Validate **********\n",
            "Epoch 102, Loss: 59.3606 +/- 17.5986, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 103, Loss: 60.8769 +/- 16.5762, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 103, Loss: 62.2182 +/- 18.2826, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 104, Loss: 60.9916 +/- 16.3829, Time: 3.18\n",
            "********** Validate **********\n",
            "Epoch 104, Loss: 59.0781 +/- 17.8490, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 105, Loss: 61.6766 +/- 16.2384, Time: 3.24\n",
            "********** Validate **********\n",
            "Epoch 105, Loss: 60.1462 +/- 16.3106, Time: 0.52\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 106, Loss: 60.0260 +/- 16.8519, Time: 3.18\n",
            "********** Validate **********\n",
            "Epoch 106, Loss: 61.7444 +/- 16.0507, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 107, Loss: 60.2680 +/- 16.8676, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 107, Loss: 58.2361 +/- 17.7541, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 108, Loss: 60.3223 +/- 16.3498, Time: 3.18\n",
            "********** Validate **********\n",
            "Epoch 108, Loss: 60.4146 +/- 17.6627, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 109, Loss: 59.6065 +/- 16.1225, Time: 3.23\n",
            "********** Validate **********\n",
            "Epoch 109, Loss: 58.4605 +/- 17.1870, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 110, Loss: 60.1979 +/- 16.3314, Time: 3.15\n",
            "********** Validate **********\n",
            "Epoch 110, Loss: 61.8910 +/- 16.4012, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 111, Loss: 60.0504 +/- 16.3620, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 111, Loss: 60.4534 +/- 16.3907, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 112, Loss: 59.1478 +/- 16.6074, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 112, Loss: 60.2734 +/- 16.4483, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 113, Loss: 59.2952 +/- 16.1549, Time: 3.19\n",
            "********** Validate **********\n",
            "Epoch 113, Loss: 59.8962 +/- 17.9088, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 114, Loss: 58.9172 +/- 16.4390, Time: 3.30\n",
            "********** Validate **********\n",
            "Epoch 114, Loss: 60.1190 +/- 16.9224, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 115, Loss: 58.7160 +/- 15.8210, Time: 3.32\n",
            "********** Validate **********\n",
            "Epoch 115, Loss: 58.9208 +/- 16.8609, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 116, Loss: 58.6249 +/- 16.5063, Time: 3.21\n",
            "********** Validate **********\n",
            "Epoch 116, Loss: 61.0153 +/- 16.1753, Time: 0.53\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 117, Loss: 58.1103 +/- 15.6954, Time: 3.31\n",
            "********** Validate **********\n",
            "Epoch 117, Loss: 59.1966 +/- 16.6289, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 118, Loss: 58.2976 +/- 15.7918, Time: 3.25\n",
            "********** Validate **********\n",
            "Epoch 118, Loss: 58.0710 +/- 16.0575, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 119, Loss: 58.5025 +/- 15.7077, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 119, Loss: 57.5689 +/- 17.2769, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 120, Loss: 57.7381 +/- 16.3351, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 120, Loss: 58.4061 +/- 17.0403, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 121, Loss: 58.1768 +/- 15.0818, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 121, Loss: 56.5934 +/- 16.2968, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 122, Loss: 57.7496 +/- 16.6968, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 122, Loss: 59.8566 +/- 15.7016, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 123, Loss: 57.7602 +/- 16.6230, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 123, Loss: 57.4492 +/- 15.9146, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 124, Loss: 57.3616 +/- 15.1404, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 124, Loss: 56.3378 +/- 16.6993, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 125, Loss: 56.6503 +/- 15.6297, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 125, Loss: 57.5772 +/- 16.7943, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 126, Loss: 56.9900 +/- 15.3929, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 126, Loss: 58.6372 +/- 17.5431, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 127, Loss: 56.9363 +/- 15.8078, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 127, Loss: 57.0563 +/- 16.2227, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 128, Loss: 57.0602 +/- 15.9116, Time: 2.99\n",
            "********** Validate **********\n",
            "Epoch 128, Loss: 56.2898 +/- 16.1817, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 129, Loss: 57.3801 +/- 15.0358, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 129, Loss: 60.8277 +/- 15.9016, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 130, Loss: 56.8945 +/- 15.5144, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 130, Loss: 57.0283 +/- 16.0747, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 131, Loss: 57.3980 +/- 14.6620, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 131, Loss: 57.6229 +/- 16.9779, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 132, Loss: 56.5853 +/- 16.2008, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 132, Loss: 57.0413 +/- 17.0586, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 133, Loss: 57.1793 +/- 16.3899, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 133, Loss: 56.0924 +/- 15.5953, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 134, Loss: 55.9938 +/- 15.7762, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 134, Loss: 58.8905 +/- 16.2038, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 135, Loss: 57.2663 +/- 15.0953, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 135, Loss: 54.9908 +/- 15.9915, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 136, Loss: 56.1982 +/- 14.9872, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 136, Loss: 56.1940 +/- 16.7058, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 137, Loss: 56.7606 +/- 15.3859, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 137, Loss: 55.1967 +/- 16.1507, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 138, Loss: 56.1101 +/- 15.5995, Time: 3.19\n",
            "********** Validate **********\n",
            "Epoch 138, Loss: 56.9030 +/- 16.0839, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 139, Loss: 56.5307 +/- 15.9996, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 139, Loss: 56.6515 +/- 15.8439, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 140, Loss: 56.1580 +/- 15.3459, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 140, Loss: 54.9878 +/- 16.1467, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 141, Loss: 56.6044 +/- 15.1537, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 141, Loss: 57.7969 +/- 17.0190, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 142, Loss: 56.0493 +/- 14.9249, Time: 3.18\n",
            "********** Validate **********\n",
            "Epoch 142, Loss: 56.6199 +/- 16.7437, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 143, Loss: 56.0669 +/- 15.8695, Time: 3.32\n",
            "********** Validate **********\n",
            "Epoch 143, Loss: 59.2759 +/- 15.8861, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 144, Loss: 55.4063 +/- 15.2459, Time: 3.20\n",
            "********** Validate **********\n",
            "Epoch 144, Loss: 58.2679 +/- 16.2786, Time: 0.52\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 145, Loss: 55.1543 +/- 14.8789, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 145, Loss: 57.9068 +/- 16.7096, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 146, Loss: 54.4923 +/- 14.4632, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 146, Loss: 57.1658 +/- 16.9521, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 147, Loss: 55.3972 +/- 15.4710, Time: 3.21\n",
            "********** Validate **********\n",
            "Epoch 147, Loss: 56.7640 +/- 15.8562, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 148, Loss: 55.0989 +/- 15.8482, Time: 3.19\n",
            "********** Validate **********\n",
            "Epoch 148, Loss: 55.9366 +/- 15.8992, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 149, Loss: 54.6679 +/- 15.5105, Time: 3.15\n",
            "********** Validate **********\n",
            "Epoch 149, Loss: 58.8342 +/- 15.4089, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 150, Loss: 54.3901 +/- 15.1373, Time: 3.16\n",
            "********** Validate **********\n",
            "Epoch 150, Loss: 55.9128 +/- 15.8843, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 151, Loss: 54.0280 +/- 16.4635, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 151, Loss: 55.1581 +/- 15.2236, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 152, Loss: 54.1892 +/- 15.1304, Time: 3.15\n",
            "********** Validate **********\n",
            "Epoch 152, Loss: 55.1786 +/- 16.1417, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 153, Loss: 53.7207 +/- 14.3754, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 153, Loss: 56.1500 +/- 16.1162, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 154, Loss: 53.6396 +/- 14.1191, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 154, Loss: 55.8051 +/- 16.2232, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 155, Loss: 53.7453 +/- 13.9778, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 155, Loss: 55.2924 +/- 15.5905, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 156, Loss: 53.2580 +/- 14.5499, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 156, Loss: 54.3641 +/- 15.6500, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 157, Loss: 52.7058 +/- 14.4663, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 157, Loss: 53.9307 +/- 15.2530, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 158, Loss: 52.5081 +/- 14.1592, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 158, Loss: 53.4754 +/- 15.7475, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 159, Loss: 52.2073 +/- 14.0086, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 159, Loss: 53.5097 +/- 15.5466, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 160, Loss: 52.1142 +/- 14.4803, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 160, Loss: 53.4595 +/- 15.3170, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 161, Loss: 52.3540 +/- 15.6887, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 161, Loss: 53.3878 +/- 15.5882, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 162, Loss: 52.7314 +/- 14.0550, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 162, Loss: 54.5287 +/- 15.0791, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 163, Loss: 53.0969 +/- 14.3267, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 163, Loss: 53.8265 +/- 15.1958, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 164, Loss: 52.8995 +/- 14.0964, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 164, Loss: 53.3357 +/- 15.1876, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 165, Loss: 52.3338 +/- 14.5087, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 165, Loss: 52.7350 +/- 14.9857, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 166, Loss: 52.4860 +/- 14.5760, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 166, Loss: 53.1531 +/- 15.0595, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 167, Loss: 52.4400 +/- 14.6851, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 167, Loss: 53.0172 +/- 14.9540, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 168, Loss: 52.4973 +/- 15.0913, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 168, Loss: 53.1187 +/- 14.9790, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 169, Loss: 52.2029 +/- 14.6351, Time: 3.12\n",
            "********** Validate **********\n",
            "Epoch 169, Loss: 55.6130 +/- 15.5541, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 170, Loss: 52.3914 +/- 13.9804, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 170, Loss: 53.2057 +/- 14.8026, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 171, Loss: 52.4274 +/- 14.0274, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 171, Loss: 52.1667 +/- 14.3119, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 172, Loss: 51.9480 +/- 14.4073, Time: 3.23\n",
            "********** Validate **********\n",
            "Epoch 172, Loss: 55.0365 +/- 14.5870, Time: 0.51\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 173, Loss: 51.6841 +/- 14.1842, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 173, Loss: 55.3565 +/- 14.4452, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 174, Loss: 52.1008 +/- 14.8873, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 174, Loss: 52.5905 +/- 14.2389, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 175, Loss: 51.7559 +/- 14.2955, Time: 3.16\n",
            "********** Validate **********\n",
            "Epoch 175, Loss: 52.1964 +/- 14.3956, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 176, Loss: 51.5234 +/- 13.3782, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 176, Loss: 53.0493 +/- 15.0722, Time: 0.45\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 177, Loss: 51.2065 +/- 13.6964, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 177, Loss: 52.4067 +/- 14.2215, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 178, Loss: 51.0001 +/- 13.5241, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 178, Loss: 51.9418 +/- 13.9686, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 179, Loss: 50.6443 +/- 13.7835, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 179, Loss: 51.9143 +/- 14.1883, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 180, Loss: 50.9416 +/- 13.9501, Time: 3.18\n",
            "********** Validate **********\n",
            "Epoch 180, Loss: 52.8633 +/- 14.1397, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 181, Loss: 51.0809 +/- 14.0569, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 181, Loss: 52.8254 +/- 14.5416, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 182, Loss: 51.0767 +/- 13.7050, Time: 3.05\n",
            "********** Validate **********\n",
            "Epoch 182, Loss: 51.6504 +/- 13.9601, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 183, Loss: 51.2329 +/- 14.0793, Time: 3.16\n",
            "********** Validate **********\n",
            "Epoch 183, Loss: 51.2151 +/- 13.6069, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 184, Loss: 51.9047 +/- 13.6219, Time: 3.09\n",
            "********** Validate **********\n",
            "Epoch 184, Loss: 51.7005 +/- 13.7505, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 185, Loss: 51.5976 +/- 14.5941, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 185, Loss: 53.6506 +/- 13.9836, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 186, Loss: 51.4090 +/- 14.4434, Time: 3.01\n",
            "********** Validate **********\n",
            "Epoch 186, Loss: 54.1631 +/- 13.9909, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 187, Loss: 51.7666 +/- 14.4474, Time: 3.05\n",
            "********** Validate **********\n",
            "Epoch 187, Loss: 51.3534 +/- 13.1479, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 188, Loss: 51.7173 +/- 14.3023, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 188, Loss: 51.4386 +/- 14.0407, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 189, Loss: 50.9265 +/- 13.7751, Time: 3.06\n",
            "********** Validate **********\n",
            "Epoch 189, Loss: 52.1061 +/- 13.7718, Time: 0.46\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 190, Loss: 51.4552 +/- 14.2140, Time: 3.05\n",
            "********** Validate **********\n",
            "Epoch 190, Loss: 50.4372 +/- 13.6170, Time: 0.44\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 191, Loss: 50.8591 +/- 13.6812, Time: 3.08\n",
            "********** Validate **********\n",
            "Epoch 191, Loss: 52.0027 +/- 13.2017, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 192, Loss: 50.4173 +/- 13.5954, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 192, Loss: 51.7543 +/- 13.5561, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 193, Loss: 50.4579 +/- 14.6672, Time: 3.13\n",
            "********** Validate **********\n",
            "Epoch 193, Loss: 51.0813 +/- 13.5146, Time: 0.49\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 194, Loss: 50.2934 +/- 13.8420, Time: 3.07\n",
            "********** Validate **********\n",
            "Epoch 194, Loss: 51.0314 +/- 13.1893, Time: 0.50\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 195, Loss: 50.6287 +/- 13.9497, Time: 3.10\n",
            "********** Validate **********\n",
            "Epoch 195, Loss: 51.1500 +/- 13.2941, Time: 0.52\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 196, Loss: 50.9099 +/- 13.9530, Time: 3.11\n",
            "********** Validate **********\n",
            "Epoch 196, Loss: 50.5462 +/- 13.5913, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 197, Loss: 50.4924 +/- 13.8925, Time: 3.28\n",
            "********** Validate **********\n",
            "Epoch 197, Loss: 52.1965 +/- 14.6062, Time: 0.48\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 198, Loss: 50.0048 +/- 14.3161, Time: 3.17\n",
            "********** Validate **********\n",
            "Epoch 198, Loss: 51.4162 +/- 13.6216, Time: 0.47\n",
            "\n",
            "#################### Train ####################\n",
            "Epoch 199, Loss: 49.9577 +/- 13.8985, Time: 3.14\n",
            "********** Validate **********\n",
            "Epoch 199, Loss: 51.5163 +/- 13.7847, Time: 0.48\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "MYg_zaULSWpy",
        "outputId": "8b6bc03b-5c28-4e6c-8f1e-132da8dc43dc"
      },
      "source": [
        "Xtest = torch.stack([tup[0] for tup in test_set])\n",
        "Xtest = Xtest.to(args['device'])\n",
        "\n",
        "ytest = torch.stack([tup[1] for tup in test_set])\n",
        "ypred = net(Xtest).cpu().data\n",
        "\n",
        "data = torch.cat((ytest, ypred), axis=1)\n",
        "\n",
        "df_results = pd.DataFrame(data, columns=['ypred', 'ytest'])\n",
        "df_results.head(20)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ypred</th>\n",
              "      <th>ytest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tensor(352.)</td>\n",
              "      <td>tensor(258.5137)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tensor(156.)</td>\n",
              "      <td>tensor(116.8862)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tensor(12.)</td>\n",
              "      <td>tensor(9.5872)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tensor(2.)</td>\n",
              "      <td>tensor(0.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tensor(391.)</td>\n",
              "      <td>tensor(307.9059)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tensor(391.)</td>\n",
              "      <td>tensor(301.5105)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tensor(84.)</td>\n",
              "      <td>tensor(169.5561)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tensor(487.)</td>\n",
              "      <td>tensor(609.4336)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tensor(176.)</td>\n",
              "      <td>tensor(184.1704)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tensor(157.)</td>\n",
              "      <td>tensor(71.7680)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>tensor(82.)</td>\n",
              "      <td>tensor(87.1024)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tensor(186.)</td>\n",
              "      <td>tensor(94.7267)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tensor(277.)</td>\n",
              "      <td>tensor(323.3112)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tensor(264.)</td>\n",
              "      <td>tensor(325.8649)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>tensor(312.)</td>\n",
              "      <td>tensor(350.5137)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>tensor(56.)</td>\n",
              "      <td>tensor(22.5946)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tensor(370.)</td>\n",
              "      <td>tensor(176.4183)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>tensor(14.)</td>\n",
              "      <td>tensor(89.8691)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>tensor(124.)</td>\n",
              "      <td>tensor(165.2219)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tensor(427.)</td>\n",
              "      <td>tensor(396.1453)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ypred             ytest\n",
              "0   tensor(352.)  tensor(258.5137)\n",
              "1   tensor(156.)  tensor(116.8862)\n",
              "2    tensor(12.)    tensor(9.5872)\n",
              "3     tensor(2.)        tensor(0.)\n",
              "4   tensor(391.)  tensor(307.9059)\n",
              "5   tensor(391.)  tensor(301.5105)\n",
              "6    tensor(84.)  tensor(169.5561)\n",
              "7   tensor(487.)  tensor(609.4336)\n",
              "8   tensor(176.)  tensor(184.1704)\n",
              "9   tensor(157.)   tensor(71.7680)\n",
              "10   tensor(82.)   tensor(87.1024)\n",
              "11  tensor(186.)   tensor(94.7267)\n",
              "12  tensor(277.)  tensor(323.3112)\n",
              "13  tensor(264.)  tensor(325.8649)\n",
              "14  tensor(312.)  tensor(350.5137)\n",
              "15   tensor(56.)   tensor(22.5946)\n",
              "16  tensor(370.)  tensor(176.4183)\n",
              "17   tensor(14.)   tensor(89.8691)\n",
              "18  tensor(124.)  tensor(165.2219)\n",
              "19  tensor(427.)  tensor(396.1453)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9xk7MUsV9ZY"
      },
      "source": [
        "Gráfico de convergência"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "41JSi_7zV7RH",
        "outputId": "657b5614-17c4-44c3-f7c8-ea8b6cbab6d0"
      },
      "source": [
        "plt.figure(figsize=(20, 9))\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(test_losses, label='Test', linewidth=3, alpha=0.5)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.title('Convergence', fontsize=16)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTLPHMKaV_vL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}